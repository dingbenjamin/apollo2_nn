{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import sklearn\n",
    "import keras.utils\n",
    "import sys\n",
    "import os\n",
    "from python_speech_features import mfcc\n",
    "from keras import Sequential, regularizers\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from numpy import argmax\n",
    "from scipy.io.wavfile import read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_categorical(one_hot):\n",
    "    return [argmax(x) for x in one_hot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(labels):\n",
    "    return [1 if x == 1 else 0 for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_fann_dat(features, classes, output_path):\n",
    "  matrix = df.values\n",
    "  if len(features) != len(classes):\n",
    "    raise Exception(\"Sample lengths not the same\")\n",
    "  num_samples = len(features)\n",
    "  num_features = features.shape[1]\n",
    "  num_classes = classes.shape[1]\n",
    "  \n",
    "  try:\n",
    "    f = open(output_path, 'w')\n",
    "    \n",
    "    # Write first line\n",
    "    header_line = '{} {} {}\\n'.format(num_samples, num_features, num_classes)\n",
    "    f.write(header_line)\n",
    "    \n",
    "    # Write remaining lines\n",
    "    for i in range(num_samples):\n",
    "      input_line = ''\n",
    "      for j in range(num_features):\n",
    "        input_line += '{} '.format(features[i][j])\n",
    "      input_line += '\\n'\n",
    "      \n",
    "      output_line = ''\n",
    "      for j in range(num_classes):\n",
    "        output_line += '{} '.format(classes[i][j])\n",
    "      output_line += '\\n'\n",
    "      f.write(input_line)\n",
    "      f.write(output_line)\n",
    "  finally:\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONS = {'W':'Anger',\n",
    "            'L':'Boredom',\n",
    "            'E':'Disgust',\n",
    "            'A':'Fear',\n",
    "            'F':'Happiness',\n",
    "            'T':'Sadness',\n",
    "            'N':'Neutral'\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positions 1-2: number of speaker\n",
    "\n",
    "Positions 3-5: code for text\n",
    "\n",
    "Position 6: emotion (sorry, letter stands for german emotion word)\n",
    "\n",
    "Position 7: if there are more than two versions these are numbered a, b, c ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_INDICES = {'speaker':range(0, 1),\n",
    "                    'text':range(2,4),\n",
    "                    'emotion':5,\n",
    "                    'version':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './EmoDB/wav/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "BITRATE = 256000\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_EMOTIONS = {'Happiness':0, 'Anger':1, 'Sadness':2, 'Neutral':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MFCC = 25\n",
    "NUM_LAYERS = 3\n",
    "NUM_NEURONS = 30\n",
    "DESIRED_ACC = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "raw = []\n",
    "\n",
    "for filename in os.listdir(PATH):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Output label\n",
    "        emotion = EMOTIONS[filename[FILENAME_INDICES['emotion']]]\n",
    "        if emotion in USED_EMOTIONS.keys():\n",
    "            outputs.append(USED_EMOTIONS[emotion])\n",
    "            # Input .wav\n",
    "            wav = read(PATH + filename)\n",
    "            raw.append(np.array(wav[1],dtype=float))\n",
    "    else:\n",
    "        raise Exception('Invalid emotion label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features via MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window size is the length of the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for signal in raw:\n",
    "    duration = len(signal)/SAMPLE_RATE\n",
    "    features = mfcc(signal, samplerate=SAMPLE_RATE, winlen=duration, nfft=len(signal), numcep=NUM_MFCC)\n",
    "    inputs.append(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_normalised = [sample[0] for sample in inputs]\n",
    "inputs_normalised = sklearn.preprocessing.scale(inputs_normalised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data for test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(inputs_normalised, outputs, test_size=0.33, random_state=42)\n",
    "y_train_split = keras.utils.to_categorical(y_train_split, num_classes=len(USED_EMOTIONS))\n",
    "y_test_split = keras.utils.to_categorical(y_test_split, num_classes=len(USED_EMOTIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.7767857142857143\n",
      "112/112 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.7946428571428571\n",
      "112/112 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.8035714285714286\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "while acc < DESIRED_ACC:\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add first hidden layer\n",
    "    model.add(Dense(NUM_NEURONS, \n",
    "                    activation='sigmoid', \n",
    "                    input_dim=NUM_MFCC))\n",
    "    \n",
    "    # Add hidden layers\n",
    "    for i in range(NUM_LAYERS - 1):\n",
    "        model.add(Dense(NUM_NEURONS, activation='sigmoid'))\n",
    "    \n",
    "    # Add output layer\n",
    "    model.add(Dense(len(USED_EMOTIONS), activation='softmax'))\n",
    "    \n",
    "    # Compile and evaluate\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=keras.optimizers.SGD(),\n",
    "                    metrics=['accuracy'])    \n",
    "    model.fit(x_train_split, y_train_split, epochs=1000, batch_size=5, verbose=0)\n",
    "    loss, acc = model.evaluate(x_test_split, y_test_split)\n",
    "    print('Accuracy: ' + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Data for FannTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fann_dat(x_train_split, y_train_split, 'emotion_train.dat')\n",
    "to_fann_dat(x_train_split, y_train_split, 'emotion_test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
